{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4ca983",
   "metadata": {},
   "source": [
    "# Alzheimer’s Disease Classification (Demented vs Non-demented)\n",
    "\n",
    "This notebook provides a **fully reproducible** end-to-end machine learning workflow for binary classification of Alzheimer’s disease status using **demographic, clinical, and MRI-derived features**.\n",
    "\n",
    "**Target:** `Group` (\"Demented\" vs \"Nondemented\").\n",
    "\n",
    "## Academic / healthcare ML best-practice considerations\n",
    "- We implement a **group-aware train/test split** (when a subject identifier exists) to reduce optimistic bias due to repeated measures.\n",
    "- We use **pipelines** and a **ColumnTransformer** to avoid data leakage (fit preprocessing only on training data).\n",
    "- We report multiple metrics (Accuracy, Precision, Recall, F1) and discrimination performance (ROC-AUC) alongside confusion matrices and ROC curves.\n",
    "\n",
    "---\n",
    "\n",
    "## Reproducibility\n",
    "- Set a fixed random seed.\n",
    "- Print library versions.\n",
    "- Use deterministic splits and model settings where applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a223815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except OSError:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "sns.set_context('notebook')\n",
    "\n",
    "print('Python:', sys.version.split()[0])\n",
    "print('scikit-learn:', sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69101e9c",
   "metadata": {},
   "source": [
    "## 1) Load dataset\n",
    "\n",
    "To keep this notebook runnable from scratch in different environments, we attempt to automatically locate a `*.csv` file in the current directory. If you have multiple CSV files, set `DATA_PATH` explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = Path.cwd()\n",
    "csv_candidates = sorted(PROJECT_DIR.glob('*.csv'))\n",
    "\n",
    "if len(csv_candidates) == 0:\n",
    "    raise FileNotFoundError(\n",
    "        'No CSV file found in the current directory. '\n",
    "        'Place the dataset CSV next to this notebook or set DATA_PATH manually.'\n",
    "    )\n",
    "\n",
    "DATA_PATH = csv_candidates[0]\n",
    "print('Using dataset:', DATA_PATH.name)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32458738",
   "metadata": {},
   "source": [
    "## 2) Exploratory Data Analysis (EDA)\n",
    "\n",
    "We examine:\n",
    "- Dataset structure and data types\n",
    "- Missing values\n",
    "- Summary statistics\n",
    "- Basic distribution plots (including target prevalence)\n",
    "\n",
    "This step helps identify data quality issues and informs preprocessing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', df.shape)\n",
    "display(df.head(10))\n",
    "print('\\nColumns:')\n",
    "display(pd.DataFrame({'column': df.columns, 'dtype': df.dtypes.astype(str)}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types / non-null counts (compact)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93452740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values count and percentage\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_table = pd.DataFrame({'missing_count': missing, 'missing_pct': missing_pct})\n",
    "display(missing_table[missing_table.missing_count > 0])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "missing_pct[missing_pct > 0].plot(kind='bar')\n",
    "plt.title('Missingness by Feature (%)')\n",
    "plt.ylabel('Missing %')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics: numeric and categorical\n",
    "display(df.describe(include='all').T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Group' not in df.columns:\n",
    "    raise KeyError('Expected target column `Group` not found. Available columns: ' + ', '.join(df.columns))\n",
    "\n",
    "print('Target distribution (raw):')\n",
    "display(df['Group'].value_counts(dropna=False))\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='Group', order=df['Group'].value_counts().index)\n",
    "plt.title('Target Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numeric features (EDA)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr = df[numeric_cols].corr(numeric_only=True)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr, cmap='vlag', center=0, square=True)\n",
    "    plt.title('Correlation Heatmap (Numeric Features)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric features for correlation heatmap.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34acf0",
   "metadata": {},
   "source": [
    "## 3) Define binary classification task\n",
    "\n",
    "We map the target `Group` to a binary label:\n",
    "- `Demented` → 1\n",
    "- `Nondemented` / `Non-demented` → 0\n",
    "\n",
    "We also remove non-informative identifiers (e.g., subject/MRI identifiers) from the feature set to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc24d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Group'\n",
    "id_like_cols = [\n",
    "    'MRI ID',\n",
    "    'MR ID',\n",
    "    'Subject',\n",
    "    'Subject ID',\n",
    "    'PatientID',\n",
    "    'Patient ID',\n",
    "    'ID',\n",
    "    'RecordID',\n",
    "]\n",
    "\n",
    "group_col = 'MRI ID' if 'MRI ID' in df.columns else None\n",
    "groups = df[group_col].copy() if group_col is not None else None\n",
    "\n",
    "# Normalize target labels robustly\n",
    "y_raw = df[target_col].astype(str).str.strip().str.lower()\n",
    "label_map = {\n",
    "    'demented': 1,\n",
    "    'nondemented': 0,\n",
    "    'non-demented': 0,\n",
    "    'non demented': 0,\n",
    "}\n",
    "\n",
    "if not set(y_raw.unique()).issubset(set(label_map.keys())):\n",
    "    raise ValueError(\n",
    "        'Unexpected target labels in `Group`. '\n",
    "        f'Observed: {sorted(y_raw.unique())}. '\n",
    "        f'Expected subset of: {sorted(label_map.keys())}.'\n",
    "    )\n",
    "\n",
    "y = y_raw.map(label_map).astype(int)\n",
    "\n",
    "cols_to_drop = [c for c in id_like_cols if c in df.columns]\n",
    "X = df.drop(columns=[target_col] + cols_to_drop)\n",
    "\n",
    "print('Dropped identifier columns:', cols_to_drop)\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Positive class prevalence (Demented=1):', y.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4facd8",
   "metadata": {},
   "source": [
    "## 4) Train/Test split\n",
    "\n",
    "Healthcare datasets frequently contain repeated measures per subject (e.g., multiple visits).\n",
    "\n",
    "If a subject identifier exists (here: `MRI ID`), we perform a **group-aware split** so that the same subject does not appear in both train and test sets. This reduces leakage and yields a more realistic evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "\n",
    "if groups is not None:\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "    X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "    y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "    print(f'Group-aware split using `{group_col}`:')\n",
    "    print('  Train subjects:', groups.iloc[train_idx].nunique())\n",
    "    print('  Test subjects :', groups.iloc[test_idx].nunique())\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    print('Stratified random split (no group column found).')\n",
    "\n",
    "print('Train size:', X_train.shape, 'Test size:', X_test.shape)\n",
    "print('Train prevalence:', y_train.mean().round(3), 'Test prevalence:', y_test.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cfb8b",
   "metadata": {},
   "source": [
    "## 5) Preprocessing pipeline\n",
    "\n",
    "We build an explicit preprocessing pipeline:\n",
    "- **Missing values**: median for numeric, most frequent for categorical\n",
    "- **Categorical encoding**: one-hot encoding\n",
    "- **Scaling**: standardization for numeric features (important for LR/SVM/KNN)\n",
    "\n",
    "Using `Pipeline` + `ColumnTransformer` ensures preprocessing is learned **only from training data**, preventing leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X_train.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "numeric_features = [c for c in X_train.columns if c not in categorical_features]\n",
    "\n",
    "print('Categorical features:', categorical_features)\n",
    "print('Numeric features:', numeric_features)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# scikit-learn changed OneHotEncoder's sparsity parameter name.\n",
    "# This try/except keeps the notebook runnable across versions commonly found in teaching labs.\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', ohe),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29e65e",
   "metadata": {},
   "source": [
    "## 6) Train and evaluate models\n",
    "\n",
    "We train and evaluate four classical baselines commonly used for structured healthcare data:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Support Vector Machine (RBF)\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "For potential class imbalance, we use `class_weight='balanced'` where supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    'SVM (RBF)': SVC(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        probability=True,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    'KNN': KNeighborsClassifier(\n",
    "        n_neighbors=7,\n",
    "        weights='distance',\n",
    "    ),\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    name: Pipeline(steps=[('preprocess', preprocess), ('model', model)])\n",
    "    for name, model in models.items()\n",
    "}\n",
    "\n",
    "def get_score_vector(fitted_pipeline, X_input):\n",
    "    \"\"\"\n",
    "    Returns a continuous score for ROC-AUC / ROC curve when possible.\n",
    "    Preference: predict_proba -> decision_function.\n",
    "    \"\"\"\n",
    "    if hasattr(fitted_pipeline, 'predict_proba'):\n",
    "        proba = fitted_pipeline.predict_proba(X_input)\n",
    "        return proba[:, 1]\n",
    "    if hasattr(fitted_pipeline, 'decision_function'):\n",
    "        return fitted_pipeline.decision_function(X_input)\n",
    "    return None\n",
    "\n",
    "results = []\n",
    "fitted = {}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted[name] = pipe\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_score = get_score_vector(pipe, X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_score) if y_score is not None else np.nan,\n",
    "    }\n",
    "    results.append(metrics)\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470515b7",
   "metadata": {},
   "source": [
    "## 7) Evaluation: confusion matrices\n",
    "\n",
    "Confusion matrices provide an interpretable summary of errors. In clinical contexts, **false negatives** (missed dementia cases) can be particularly costly, so we examine recall and false negative counts closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85006e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, (name, pipe) in zip(axes, fitted.items()):\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        display_labels=['Non-demented (0)', 'Demented (1)'],\n",
    "        cmap='Blues',\n",
    "        ax=ax,\n",
    "        colorbar=False,\n",
    "    )\n",
    "    ax.set_title(name)\n",
    "\n",
    "plt.suptitle('Confusion Matrices (Test Set)', y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9d271",
   "metadata": {},
   "source": [
    "## 8) Evaluation: ROC curves and AUC\n",
    "\n",
    "ROC curves visualize the sensitivity/specificity trade-off across thresholds.\n",
    "We plot ROC curves for all models on the same axes for a direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6399c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.gca()\n",
    "\n",
    "for name, pipe in fitted.items():\n",
    "    RocCurveDisplay.from_estimator(pipe, X_test, y_test, ax=ax, name=name)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Chance')\n",
    "plt.title('ROC Curves (Test Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e4d2c",
   "metadata": {},
   "source": [
    "## 9) Model comparison table\n",
    "\n",
    "We summarize model performance in a single table.\n",
    "\n",
    "**Interpretation guidance (academic):**\n",
    "- **Accuracy** can be misleading under class imbalance.\n",
    "- **Recall** (sensitivity) for the demented class is critical for screening settings.\n",
    "- **Precision** relates to false positives (unnecessary follow-up).\n",
    "- **F1-score** balances precision and recall.\n",
    "- **ROC-AUC** measures ranking performance independent of a single threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cda603",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['ROC_AUC', 'F1'], ascending=False)\n",
    "display(results_df.style.format({\n",
    "    'Accuracy': '{:.3f}',\n",
    "    'Precision': '{:.3f}',\n",
    "    'Recall': '{:.3f}',\n",
    "    'F1': '{:.3f}',\n",
    "    'ROC_AUC': '{:.3f}',\n",
    "}))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "melted = results_df.melt(id_vars='Model', value_vars=['Accuracy', 'Precision', 'Recall', 'F1', 'ROC_AUC'], var_name='Metric', value_name='Score')\n",
    "sns.barplot(data=melted, x='Metric', y='Score', hue='Model')\n",
    "plt.title('Model Performance Comparison (Test Set)')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b3308",
   "metadata": {},
   "source": [
    "## 10) Notes for academic reporting\n",
    "\n",
    "For an academic assessment, consider discussing:\n",
    "- Potential sources of bias (e.g., repeated visits, demographic confounding).\n",
    "- Class imbalance and metric selection.\n",
    "- Generalization: performance on a held-out test set vs. cross-validation.\n",
    "- Clinical implications: prioritizing sensitivity vs. specificity.\n",
    "\n",
    "If you want, I can extend this notebook with:\n",
    "- Group-aware cross-validation\n",
    "- Calibration plots (reliability)\n",
    "- Feature importance (RF) and coefficients (LR) with confidence intervals\n",
    "- Threshold tuning to meet a target sensitivity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
